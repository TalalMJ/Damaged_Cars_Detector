# 2: Damage location
import numpy as np
from numpy import asarray
import os
import pandas as pd
import random
import urllib.request
from IPython.display import Image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from matplotlib import image
from matplotlib import pyplot
import seaborn as sns
sns.set_style("whitegrid")
from PIL import Image , ImageFont
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

import keras
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, GlobalAveragePooling2D, InputLayer

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing import image
from tensorflow.keras import layers
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.layers import ZeroPadding2D, Dropout 
from tensorflow.keras.models import Model
from tensorflow.keras import optimizers
from tensorflow.keras.applications import VGG16 ,Xception ,ResNet50 ,MobileNet ,DenseNet121 ,EfficientNetB1, VGG19, InceptionV3, mobilenet_v2
## Data Reading
##### Reading front damaged cars
list_images_front= []
name_front = []
for dirname, _, filenames in os.walk("C:\\Users\\user\\T5\\PROJECT\\Deep Learning\\Images\\2\\Front"):
    for filename in filenames:
        list_images_front.append(os.path.join(dirname, filename))
        name_front.append(filename)
> ##### plotting front damaged cars
front = list_images_front
plt.figure(figsize=(12, 12))
ran_num = []
for i in range(0,9):
    n = random.randint(0,len(front))
    ran_num.append(n)
for i in range(9):
    ax= plt.subplot(3, 3, i + 1)
    plt.imshow(mpimg.imread(front[ran_num[i]]))
    plt.title("Front Damage")
    plt.axis("off")
> ##### Saving the front damaged cars list into a dataframe
df_front = pd.DataFrame()
df_front["File_Name"] = name_front
df_front["Class"] = "Front"
df_front.head()
df_front.info
list_images_side = []
name_side = []
for dirname_2, _, filenames_2 in os.walk("C:\\Users\\user\\T5\\PROJECT\\Deep Learning\\Images\\2\\Side"):
    for filename in filenames_2:
        list_images_side.append(os.path.join(dirname_2, filename))
        name_side.append(filename)
side = list_images_side
plt.figure(figsize=(12, 12))
ran_num = []
for i in range(0,9):
    n = random.randint(0,len(side))
    ran_num.append(n)
for i in range(9):
    ax= plt.subplot(3, 3, i + 1)
    plt.imshow(mpimg.imread(side[ran_num[i]]))
    plt.title("Side Damaged")
    plt.axis("off")
> ##### Saving the side damaged cars list into a dataframe
df_side = pd.DataFrame()
df_side["File_Name"] = name_side
df_side["Class"] = "Side"
##### Reading rear damaged cars
list_images_rear = []
name_rear = []
for dirname_2, _, filenames_2 in os.walk("C:\\Users\\user\\T5\\PROJECT\\Deep Learning\\Images\\2\\Rear"):
    for filename in filenames_2:
        list_images_rear.append(os.path.join(dirname_2, filename))
        name_rear.append(filename)
> ##### Plotting no read damaged cars
rear = list_images_rear
plt.figure(figsize=(12, 12))
ran_num = []
for i in range(0,9):
    n = random.randint(0,len(rear))
    ran_num.append(n)
for i in range(9):
    ax= plt.subplot(3, 3, i + 1)
    plt.imshow(mpimg.imread(rear[ran_num[i]]))
    plt.title("Rear Damaged")
    plt.axis("off")
> ##### Saving the rear damaged cars list into a dataframe
df_rear = pd.DataFrame()
df_rear["File_Name"] = name_rear
df_rear["Class"] = "rear"
> ##### Now, we will concat the dataframes (front, side & rear) into one dataframe.
df_all = pd.concat([df_front,df_side, df_rear], ignore_index=True)
df_all
## Preprocessing
def prepare_image(img_path):
    img = image.load_img(img_path, target_size=(128, 128))
    x = image.img_to_array(img)
    return x
images = []
labels = []
files_path = "C:/Users/user/T5/PROJECT/Deep Learning/Images/2"
directory = os.fsencode(files_path)

for folder in os.listdir(directory):
    label = os.fsdecode(folder)
    for img in os.listdir(f'C:/Users/user/T5/PROJECT/Deep Learning/Images/2/{label}'):
        img_name = os.fsdecode(img)
        images.append(prepare_image(f'C:/Users/user/T5/PROJECT/Deep Learning/Images/2/{label}/{img_name}'))
        labels.append(label)
labeling = [int(labels[w].replace('Front', "0").replace("Side",'1').replace("Rear",'2')) for w in range(len(labels))]
X_digits, Y_digits = images, labeling
X = np.array(X_digits)
Y = to_categorical(Y_digits, num_classes=3)
X.shape, Y.shape
## Data splitting
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size = .2, random_state = 42)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = .2, random_state = 42)
> ##### Shape of each dataframe
X_train.shape
X_val.shape
X_test.shape
## Early stopping, ReduceLROnPlateau, Checkpoint
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5, min_delta=0.001)
lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', verbose=1, patience=2, factor=0.2, min_lr=0.0001)
model_checkpoint = tf.keras.callbacks.ModelCheckpoint('severe_best_model.hdf5', monitor='val_accuracy', verbose=1,save_best_only=True,mode='max')

callbacks = [early_stopping, lr_reduction, model_checkpoint]
## Modeling
> ### Logistic Regression
>> We used Logistic Regression model as a baseline model
X_train_bl = X_train.reshape(4064,128*128*3)
X_val_bl = X_val.reshape(508,128*128*3)
lr = LogisticRegression()
lr.fit(X_train_bl, y_train)
print('The accuracy for training : ',lr.score(X_train_bl,y_train))
print('The accuracy for validation: ',lr.score(X_val_bl,y_val))
> ### Simple NN Model
>> First try with basic NN model 
NN_01 = Sequential([
                    InputLayer(input_shape = X_train.shape[1:]),
                    Flatten(),
                    Dense(40, activation='relu'),
                    Dense(3, activation='softmax')])

NN_01.compile(loss='categorical_crossentropy',
              optimizer='sgd',
              metrics=['accuracy'])

NN_01.summary()

print(' ')
print('------------------------------------------------------------------------------')
print(' ')

NN_01_model = NN_01.fit(X_train, y_train, epochs=5, verbose=1, validation_split=0.1)


>> Second try, we will increase the first dense layer to have 500 neural
NN_02 = Sequential([
                    InputLayer(input_shape = X_train.shape[1:]),
                    Flatten(),
                    Dense(500, activation='relu'),
                    Dense(3, activation='softmax')])

NN_02.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

NN_02.summary()

print(' ')
print('------------------------------------------------------------------------------')
print(' ')

NN_02_model = NN_02.fit(X_train, y_train, epochs=5, verbose=1, validation_split=0.1)

>> Third try, now we will change the activation function from relu to tanh
NN_03 = Sequential([
                    InputLayer(input_shape = X_train.shape[1:]),
                    Flatten(),
                    Dense(500, activation='tanh'),
                    Dense(3, activation='softmax')])

NN_03.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

NN_03.summary()

print(' ')
print('------------------------------------------------------------------------------')
print(' ')

NN_03_model = NN_03.fit(X_train, y_train, epochs=5, verbose=1, validation_split=0.1)

>> without activation function 
NN_04 = Sequential([
                    InputLayer(input_shape = X_train.shape[1:]),
                    Flatten(),
                    Dense(500),
                    Dense(3, activation='softmax')])

NN_04.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

NN_04.summary()

print(' ')
print('------------------------------------------------------------------------------')
print(' ')

NN_04_model = NN_04.fit(X_train, y_train, epochs=5, verbose=1, validation_split=0.1)


>> Fifth try, we will increase the neurals in the dense layer to 1000, using relu as an activation function
NN_05 = Sequential([
                    InputLayer(input_shape = X_train.shape[1:]),
                    Flatten(),
                    Dense(1000, activation='relu'),
                    Dense(3, activation='softmax')])

NN_05.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

NN_05.summary()

print(' ')
print('------------------------------------------------------------------------------')
print(' ')

NN_05_model = NN_05.fit(X_train, y_train, epochs=5, verbose=1, validation_split=0.1)

>> Sixth try, we will increase the neurals in the dense layer to 1500, using relu as an activation function
NN_06 = Sequential([
                    InputLayer(input_shape = X_train.shape[1:]),
                    Flatten(),
                    Dense(1500, activation='relu'),
                    Dense(3, activation='softmax')])

NN_06.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

NN_06.summary()

print(' ')
print('------------------------------------------------------------------------------')
print(' ')

NN_06_model = NN_06.fit(X_train, y_train, epochs=5, verbose=1, validation_split=0.1)


>> Now, we will try to add more layers
NN_07 = Sequential([
                    InputLayer(input_shape = X_train.shape[1:]),
                    Flatten(),
                    Dense(500, activation='relu'),
                    Dense(250, activation='relu'),
                    Dense(3, activation='softmax')])

NN_07.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

NN_07.summary()

print(' ')
print('------------------------------------------------------------------------------')
print(' ')

NN_07_model = NN_07.fit(X_train, y_train, epochs=5, verbose=1, validation_split=0.1)


>> Adding more layers too
NN_08 = Sequential([
                    InputLayer(input_shape = X_train.shape[1:]),
                    Flatten(),
                    Dense(500, activation='relu'),
                    Dense(250, activation='relu'),
                    Dense(125, activation='relu'),
                    Dense(75, activation='relu'),
                    Dense(3, activation='softmax')])

NN_08.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

NN_08.summary()

print(' ')
print('------------------------------------------------------------------------------')
print(' ')

NN_08_model = NN_08.fit(X_train, y_train, epochs=5, verbose=1, validation_split=0.1)

>> #### We tried with NN model, eight times: the best one between them was number 3
> ### CNN model
>> First, we will try CNN model without dropout
CNN_01 = Sequential([
                     InputLayer(input_shape=X_train.shape[1:]),
                     Conv2D(filters=16, kernel_size=5, activation='relu', padding='same'),
                     MaxPooling2D(),
                     Conv2D(filters=32, kernel_size=5, activation='relu', padding='same'),
                     MaxPooling2D(),
                     Flatten(),
                     Dense(500, activation='relu'),
                     Dense(3, activation='softmax')])

CNN_01.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

CNN_01.summary()

print(' ')
print('------------------------------------------------------------------------------')
print(' ')

CNN_01_model = CNN_01.fit(X_train, y_train, epochs=10, verbose=1, validation_data=(X_val,y_val))
>> CNN with dropout 50%
CNN_02 = Sequential([
                     InputLayer(input_shape=X_train.shape[1:]),
                     Conv2D(filters=32, kernel_size=5, activation='relu', padding='same'),
                     MaxPooling2D(),
                     Conv2D(filters=64, kernel_size=5, activation='relu', padding='same'),
                     MaxPooling2D(),
                     Conv2D(filters=128, kernel_size=5, activation='relu', padding='same'),
                     MaxPooling2D(),
                     Flatten(),
                     Dense(512, activation='relu'),
                     Dropout(0.5),
                     Dense(3, activation='softmax')])

CNN_02.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

CNN_02.summary()

print(' ')
print('------------------------------------------------------------------------------')
print(' ')

CNN_02_model = CNN_02.fit(X_train, y_train, epochs=10, verbose=1, validation_data=(X_val,y_val))
>> CNN with a regularizer
CNN_03 = Sequential([
                     InputLayer(input_shape=X_train.shape[1:]),
                     Conv2D(filters=32, 
                            kernel_size=5, 
                            activation='relu', 
                            padding='same',
                            kernel_regularizer=keras.regularizers.l2(0.001)),
                     MaxPooling2D(),
                     Conv2D(filters=64, 
                            kernel_size=5, 
                            activation='relu', 
                            padding='same', 
                            kernel_regularizer=keras.regularizers.l2(0.001)),
                     MaxPooling2D(),
                     Conv2D(filters=128, 
                            kernel_size=5, 
                            activation='relu', 
                            padding='same', 
                            kernel_regularizer=keras.regularizers.l2(0.001)),
                     MaxPooling2D(),
                     Flatten(),
                     Dense(512, 
                           activation='relu', 
                           kernel_regularizer=keras.regularizers.l2(0.001)),
                     Dense(3, activation='softmax')])

CNN_03.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

CNN_03.summary()

print(' ')
print('------------------------------------------------------------------------------')
print(' ')

CNN_03_model = CNN_03.fit(X_train, y_train, epochs=10, verbose=1,  validation_data=(X_val, y_val))
>> CNN with more dense layers and dropout
CNN_04 = Sequential([
                     InputLayer(input_shape=X_train.shape[1:]),
                     Conv2D(filters=32, kernel_size=5, activation='relu', padding='same'),
                     MaxPooling2D(),
                     Conv2D(filters=64, kernel_size=5, activation='relu', padding='same'),
                     MaxPooling2D(),
                     Conv2D(filters=128, kernel_size=5, activation='relu', padding='same'),
                     MaxPooling2D(),
                     Flatten(),
                     Dense(256, activation='relu'),
                     Dropout(0.2),
                     Dense(512, activation='relu'),
                     Dropout(0.2),
                     Dense(3, activation='softmax')])

CNN_04.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

CNN_04.summary()

print(' ')
print('------------------------------------------------------------------------------')
print(' ')

CNN_04_model = CNN_04.fit(X_train, y_train, epochs=10, verbose=1, batch_size=300, validation_data=(X_val,y_val))
>> Using Early stopping, ReduseLROnPlataeu, checkpoint
CNN_05 = Sequential([
                     InputLayer(input_shape=X_train.shape[1:]),
                     Conv2D(filters=32, kernel_size=5, activation='relu', padding='same'),
                     MaxPooling2D(),
                     Conv2D(filters=64, kernel_size=5, activation='relu', padding='same'),
                     MaxPooling2D(),
                     Conv2D(filters=128, kernel_size=5, activation='relu', padding='same'),
                     MaxPooling2D(),
                     Flatten(),
                     Dense(256, activation='relu'),
                     Dropout(0.05),
                     Dense(512, activation='relu'),
                     Dropout(0.05),
                     Dense(3, activation='softmax')])

CNN_05.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

CNN_05.summary()

print(' ')
print('------------------------------------------------------------------------------')
print(' ')

CNN_05_model = CNN_05.fit(X_train, y_train, epochs=30, verbose=1, batch_size=128, validation_data=(X_val,y_val), callbacks=callbacks)

>> increase dropout percentage
CNN_06 = Sequential([
                     InputLayer(input_shape=X_train.shape[1:]),
                     Conv2D(filters=16, kernel_size=5, activation='relu', padding='same'),
                     MaxPooling2D(),
                     Conv2D(filters=32, kernel_size=5, activation='relu', padding='same'),
                     MaxPooling2D(),
                     Conv2D(filters=64, kernel_size=5, activation='relu', padding='same'),
                     MaxPooling2D(),
                     Flatten(),
                     Dense(128, activation='relu'),
                     Dropout(0.5),
                     Dense(256, activation='relu'),
                     Dropout(0.5),
                     Dense(3, activation='softmax')])

CNN_06.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

CNN_06.summary()

print(' ')
print('------------------------------------------------------------------------------')
print(' ')

CNN_06_model = CNN_06.fit(X_train, y_train, epochs=30, verbose=1, validation_data=(X_val,y_val), callbacks=callbacks)
> #### We used dropout and keras regularizer and still... we have an overfitting in our data. So, we wil use data augmentation as a solution for overfitting in image classification
## Data Augmentation
>> - Resize the images (180x180)
>> - Scaling/Normalization (1 to 255)
>> - Randomly flip images (Horizontally)
>> - Randomly rotate images (up to 20)
>> from [HERE](https://analyticsindiamag.com/guide-to-customized-data-augmentation-using-tensorflow/)
img_height = 180
img_width = 180

data_augmentation = tf.keras.Sequential([
           layers.experimental.preprocessing.Resizing(img_width, img_height),
           layers.experimental.preprocessing.Rescaling(1./255),
           layers.experimental.preprocessing.RandomFlip('horizontal'),
           layers.experimental.preprocessing.RandomRotation(0.2)
 ])
>> CNN using data augmentation
CNN_07 = Sequential()

CNN_07.add(data_augmentation)

CNN_07.add(Conv2D(16, activation='relu', kernel_size=(3,3)))
CNN_07.add(MaxPooling2D())

CNN_07.add(Conv2D(32, activation='relu', kernel_size=(3,3)))
CNN_07.add(MaxPooling2D())

CNN_07.add(Conv2D(64, activation='relu', kernel_size=(3,3)))
CNN_07.add(MaxPooling2D())

CNN_07.add(Flatten())

CNN_07.add(Dense(100, activation='relu'))
CNN_07.add(Dropout(0.2))

CNN_07.add(Dense(200, activation='relu'))
CNN_07.add(Dropout(0.2))

CNN_07.add(Dense(3,activation='softmax'))


CNN_07.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

print(' ')
print('------------------------------------------------------------------------------')
print(' ')

CNN_07_model = CNN_07.fit(X_train, y_train, epochs=30, verbose=1, validation_data=(X_val,y_val), callbacks=callbacks)
>> ##### plotting for cnn with augmentatoin for accurcy and loss
plt.figure(0)
plt.plot(CNN_07_model.history['accuracy'], label='training accuracy')
plt.plot(CNN_07_model.history['val_accuracy'], label='val accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.figure(1)
plt.plot(CNN_07_model.history['loss'], label='training loss')
plt.plot(CNN_07_model.history['val_loss'], label='val loss')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend();
# Transfer Learning
## Data Augmentation
early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=20, min_delta=0.001)
lr_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', verbose=1, patience=2, factor=0.2, min_lr=0.00001)
model_checkpoint = tf.keras.callbacks.ModelCheckpoint('location_model.hdf5', monitor='val_accuracy', verbose=1,save_best_only=True,mode='max')

callbacks = [early_stopping, lr_reduction, model_checkpoint]
train_datagen = ImageDataGenerator(width_shift_range=[-200,200] ## Shifting
                                    ,horizontal_flip=True, vertical_flip=True ## Flipping
                                    ,rotation_range=20, fill_mode='nearest' ## Rotation
                                    ,brightness_range=[0.5,2.0] ## Changing brightness
                                    ,featurewise_center =True,featurewise_std_normalization = True ## Standardizing images
                                    ,shear_range=0.2
                                    ,zoom_range=0.2
                                    )



datagen = ImageDataGenerator()



train_generator = train_datagen.flow(X_train,y_train, batch_size=128,)

val_generator = datagen.flow(X_val,y_val,batch_size=128,)
datagen = ImageDataGenerator(
    rotation_range = 40, 
    width_shift_range = 0.1,
    height_shift_range = 0.1, 
    brightness_range = (0.5, 1),
    shear_range=0.2,
    zoom_range = 0.2,
    horizontal_flip = True, 
    fill_mode='nearest')
> #### VGG16
vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(128,128,3))

#Freeze convolutional layers
for layer in vgg_model.layers:
    layer.trainable = False
    
x = vgg_model.output
x = Flatten()(x)
x = Dense(100, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(50, activation='relu')(x)
predictions = Dense(3, activation='softmax')(x)

vgg_model = Model(inputs = vgg_model.input, outputs=predictions)
vgg_model.compile(loss='categorical_crossentropy',
                 optimizer='nadam',
                 metrics=['accuracy'])
vgg_model.summary()
vgg_16 = vgg_model.fit_generator(train_generator,
                 validation_data=val_generator,
                 epochs=30,
                 callbacks=callbacks)
plt.figure(0)
plt.plot(vgg_16.history['accuracy'], label='training accuracy')
plt.plot(vgg_16.history['val_accuracy'], label='val accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.figure(1)
plt.plot(vgg_16.history['loss'], label='training loss')
plt.plot(vgg_16.history['val_loss'], label='val loss')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend();
# Data Augmentation
datagen = ImageDataGenerator(
    rotation_range = 40, 
    width_shift_range = 0.1,
    height_shift_range = 0.1, 
    brightness_range = (0.5, 1),
    shear_range=0.2,
    zoom_range = 0.2,
    horizontal_flip = True, 
    fill_mode='nearest')
sample_df = df_front.sample(1)
sample_generator = datagen.flow_from_dataframe(
    dataframe = sample_df,
    directory = 'Images\\2\\front',
    x_col = "File_Name",
    y_col = "Class")

plt.figure(figsize=(12, 12))
for i in range(9):
    plt.subplot(3, 3, i + 1)
    for X, y in sample_generator:
        plt.imshow(X[0]/255)
        plt.axis("off")
        break
plt.tight_layout()
plt.show()
len(list_images_rear)
Sample_list_front = random.sample(list_images_front, 498)
Sample_list_side = random.sample(list_images_side, 320)
Sample_list_rear = random.sample(list_images_rear, 345)
> Saving the images
for path in Sample_list_front:
    img = load_img(path)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)

    i = 0
    for batch in datagen.flow(x, batch_size=1,save_to_dir='C:\\Users\\user\\T5\\PROJECT\\Deep Learning\\Images\\2\\Front', save_prefix='front', save_format='jpg'):
        i += 1
        if i > 4:
            break
            

for path in Sample_list_side:
    img = load_img(path)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)

    i = 0
    for batch in datagen.flow(x, batch_size=1,save_to_dir='C:\\Users\\user\\T5\\PROJECT\\Deep Learning\\Images\\2\\Side', save_prefix='side', save_format='jpg'):
        i += 1
        if i > 4:
            break


for path in Sample_list_rear:
    img = load_img(path)
    x = img_to_array(img)
    x = x.reshape((1,) + x.shape)

    i = 0
    for batch in datagen.flow(x, batch_size=1,save_to_dir='C:\\Users\\user\\T5\\PROJECT\\Deep Learning\\Images\\2\\Rear', save_prefix='rear', save_format='jpg'):
        i += 1
        if i > 4:
            break
list_images_front_Aug = []
name_front_Aug= []
for dirname, _, filenames in os.walk("C:\\Users\\user\\T5\\PROJECT\\Deep Learning\\Images\\2\\Front"):
    for filename in filenames:
        list_images_front_Aug.append(os.path.join(dirname, filename))
        name_front_Aug.append(filename)

df_images_front_Aug = pd.DataFrame()
df_images_front_Aug["File_Name"] = name_front_Aug
df_images_front_Aug["Class"] = "front"
df_images_front_Aug
list_images_side_Aug = []
name_side_Aug= []
for dirname, _, filenames in os.walk("C:\\Users\\user\\T5\\PROJECT\\Deep Learning\\Images\\2\\Side"):
    for filename in filenames:
        list_images_side_Aug.append(os.path.join(dirname, filename))
        name_side_Aug.append(filename)

df_images_side_Aug = pd.DataFrame()
df_images_side_Aug["File_Name"] = name_side_Aug
df_images_side_Aug["Class"] = "side"
df_images_side_Aug
list_images_rear_Aug = []
name_rear_Aug= []
for dirname, _, filenames in os.walk("C:\\Users\\user\\T5\\PROJECT\\Deep Learning\\Images\\2\\Rear"):
    for filename in filenames:
        list_images_rear_Aug.append(os.path.join(dirname, filename))
        name_rear_Aug.append(filename)

df_images_rear_Aug = pd.DataFrame()
df_images_rear_Aug["File_Name"] = name_rear_Aug
df_images_rear_Aug["Class"] = "rear"
df_images_rear_Aug
df_all_images_Aug = pd.concat([df_images_front_Aug, df_images_side_Aug,df_images_rear_Aug], ignore_index=True)
df_all_images_Aug
images_Aug = []
labels_Aug = []
files_path = "C:/Users/user/T5/PROJECT/Deep Learning/Images/2"
directory = os.fsencode(files_path)

for folder in os.listdir(directory):
    label = os.fsdecode(folder)
    for img in os.listdir(f'C:/Users/user/T5/PROJECT/Deep Learning/Images/2/{label}'):
        img_name = os.fsdecode(img)
        images_Aug.append(prepare_image(f'C:/Users/user/T5/PROJECT/Deep Learning/Images/2/{label}/{img_name}'))
        labels_Aug.append(label)

label_0_1_Aug = [int(labels_Aug[w].replace('Front', "0").replace("Side",'1').replace("Rear",'2')) for w in range(len(labels_Aug))]
label_0_1_Aug
X_digits_Aug, Y_digits_Aug = images_Aug, label_0_1_Aug
X_Aug = np.array(X_digits_Aug)
Y_Aug = to_categorical(Y_digits_Aug, num_classes=3)
X_Aug.shape, Y_Aug.shape
X_train_val, X_test, y_train_val, y_test = (train_test_split(X_Aug, Y_Aug, test_size = .1, random_state = 42))
X_train, X_val, y_train, y_val = (train_test_split(X_train_val, y_train_val, test_size = .111, random_state = 42))
X_train.shape
X_val.shape
> #### VGG19
vgg_model_19 = VGG19(weights='imagenet', include_top=False, input_shape=(128,128,3))

#Freeze convolutional layers
for layer in vgg_model_19.layers:
    layer.trainable = False

x = vgg_model_19.output
x = Flatten()(x)
x = Dense(100, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(50, activation='relu')(x)
predictions = Dense(3, activation='softmax')(x)

vgg_model_19 = Model(inputs = vgg_model_19.input, outputs=predictions)
vgg_model_19.compile(loss='categorical_crossentropy',
                 optimizer='nadam',
                 metrics=['accuracy'])
vgg_model_19.summary()
vgg_19 = vgg_model_19.fit(X_train, y_train, validation_data=(X_val,y_val), epochs=20, callbacks=callbacks)
plt.figure(0)
plt.plot(vgg_19.history['accuracy'], label='training accuracy')
plt.plot(vgg_19.history['val_accuracy'], label='val accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.figure(1)
plt.plot(vgg_19.history['loss'], label='training loss')
plt.plot(vgg_19.history['val_loss'], label='val loss')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend();
> #### InceptionV3
Incep_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(128,128,3))

#Freeze convolutional layers
for layer in Incep_model.layers:
    layer.trainable = False
    
x = Incep_model.output
x = Flatten()(x)
x = Dense(200, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(100, activation='relu')(x)
predictions = Dense(3, activation='softmax')(x)

Incep_model = Model(inputs = Incep_model.input, outputs=predictions)
Incep_model.compile(loss='categorical_crossentropy',
                 optimizer='nadam',
                 metrics=['accuracy'])
Incep_model.summary()
incep = Incep_model.fit_generator(train_generator,
                 validation_data=val_generator,
                 epochs=30,
                 callbacks=callbacks)
>> ##### plotting for InceptionV3 (accuracy & loss)
plt.figure(0)
plt.plot(incep.history['accuracy'], label='training accuracy')
plt.plot(incep.history['val_accuracy'], label='val accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.figure(1)
plt.plot(incep.history['loss'], label='training loss')
plt.plot(incep.history['val_loss'], label='val loss')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend();
> #### MobileNetV2
mn2_model = mobilenet_v2.MobileNetV2(weights='imagenet', include_top=False, input_shape=(128,128,3))

#Freeze convolutional layers
for layer in mn2_model.layers:
    layer.trainable = False
    
x = mn2_model.output
x = Flatten()(x)
x = Dense(100, activation='relu')(x)
x = Dropout(0.5)(x)
x = Dense(50, activation='relu')(x)
predictions = Dense(3, activation='softmax')(x)

mn2_model = Model(inputs = mn2_model.input, outputs=predictions)
mn2_model.compile(loss='categorical_crossentropy',
                 optimizer='nadam',
                 metrics=['accuracy'])
mn2_model.summary()
mobilev2 = mn2_model.fit(X_train, y_train,  validation_data=(X_val,y_val), epochs=20, callbacks=callbacks)
>> ##### plotting for MobileNetV2 (accuracy & loss)
plt.figure(0)
plt.plot(mobilev2.history['accuracy'], label='training accuracy')
plt.plot(mobilev2.history['val_accuracy'], label='val accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.figure(1)
plt.plot(mobilev2.history['loss'], label='training loss')
plt.plot(mobilev2.history['val_loss'], label='val loss')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend();
from sklearn.metrics import accuracy_score

### Loading the best model
from keras.models import load_model
model = load_model('location_best_model.hdf5')
### test our model and build a pipe
print('Accuracy of our model on test data: ', model.evaluate(X_test,y_test)[1]*100,'%')
## build a pipe for severity check
def location(img, model):
    urllib.request.urlretrieve(img, 'save.jpg')
    img = load_img('save.jpg', target_size=(128,128))
    x = img_to_array(img)
    x = x.reshape((1,)+x.shape)/255
    pred = model.predict(x)
    pred_labels = np.argmax(pred, axis=1)
    d = {0:'Front', 1:'Rear', 2:'Side'}
    for key in d.keys():
        if pred_labels[0] == key:
            print("Validating location of damage....Result:",d[key])
    
## Try our model with damaged car
https://image.shutterstock.com/image-photo/zaporozhye-ukraine-november-12-2019-600w-1912770286.jpg
location("http://repairablecars-forsale.com/photos/Exotic_Wrecked_Cars_F430_Spider_Red_Ferrari.jpg", model)
